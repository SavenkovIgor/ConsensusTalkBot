{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "413b2b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# print(openai.Engine.list())\n",
    "\n",
    "def print_lines(text, max_line_length=120):\n",
    "    lines = []\n",
    "    line = \"\"\n",
    "    for word in text.split():\n",
    "        if len(line + word) > max_line_length:\n",
    "            lines.append(line)\n",
    "            line = \"\"\n",
    "        line += word + \" \"\n",
    "    lines.append(line)\n",
    "\n",
    "    for line in lines:\n",
    "        print(line)\n",
    "\n",
    "class ChatEngine:\n",
    "    model = \"\"\n",
    "    temp = 0\n",
    "\n",
    "    def __init__(self, model=\"gpt-3.5-turbo\", temp=0):\n",
    "        self.model = model\n",
    "        self.temp = temp\n",
    "\n",
    "class Chat:\n",
    "    messages: list = []\n",
    "    engine: ChatEngine\n",
    "\n",
    "    def __init__(self, engine, system_message, user_messages = []):\n",
    "        self.engine = engine\n",
    "        self.messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "        self.messages.extend([{\"role\": \"user\", \"content\": message} for message in user_messages])\n",
    "\n",
    "    def get_answer(self, user_message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.engine.model,\n",
    "            messages=self.messages,\n",
    "            temperature=self.engine.temp,\n",
    "        )\n",
    "        answer = response.choices[0].message[\"content\"]\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d416fa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restate version: If I understand correctly, you agree that there is a problem with safety, but you are concerned that people are not taking it seriously enough. Just because the problem already exists doesn't mean we should make it worse.\n",
      "\n",
      "Polite version: Excuse me, may I ask for clarification on your statement? It seems that you agree that there is a safety issue, but you are worried that people are not taking it seriously enough. You also mentioned that just because the problem already exists, it doesn't mean we should make it worse.\n",
      "\n",
      "Validate version: Thank you for sharing your thoughts on this matter. It appears that you acknowledge the existence of a safety issue, but you are concerned that people are not taking it seriously enough. You also mentioned that we should not make the problem worse just because it already exists.\n"
     ]
    }
   ],
   "source": [
    "message_versions_prompt = \"\"\"\n",
    "You are a Conversation Improvement robot.Your main goal is, \\\n",
    "to support the truth seeking conversation style, \\\n",
    "your secondary goals is to try formulate messages in a  \\\n",
    "way that don't creates side conversations if possible, \\\n",
    "and replace thems definitions with more precise ones if necessary. \\\n",
    "Your message examples should be in the same language as user message. \\\n",
    "Take user message embrased with three backquotes, \\\n",
    "and create 3 different versions of this message.\n",
    "\n",
    "Your output format is:\n",
    "Restate version: <restate, localized version of the message>\n",
    "\n",
    "Polite version: <polite, localized version of the message>\n",
    "\n",
    "Validate version: <validate, localized version of the message>\n",
    "\n",
    "{1}\n",
    "\n",
    "User message: ```{0}```\n",
    "\"\"\"\n",
    "\n",
    "def message_versions(user_message):\n",
    "    engine = ChatEngine()\n",
    "    chat = Chat(engine, message_versions_prompt.format(user_message, \"\"))\n",
    "    answer = chat.get_answer(\"\")\n",
    "    return answer\n",
    "\n",
    "print(message_versions(\"\"\"\"\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
